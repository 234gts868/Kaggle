{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "093e6bcbd039d3dce06f32c47e4bfa6c69d30fe1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "o_7zdELmhGgn",
    "outputId": "63e5fc1e-53f9-425b-e1b8-fff56f0ac84e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "6e29213d819811e44eea35a8b87af5276c7ce27b",
    "colab": {},
    "colab_type": "code",
    "id": "13psF-UxlLn1"
   },
   "outputs": [],
   "source": [
    "def splitReviewsLabels(lines):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for review in tqdm(lines):\n",
    "        rev = reviewToX(review)\n",
    "        label = reviewToY(review)\n",
    "        reviews.append(rev[:512])\n",
    "        labels.append(label)\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c0ce0e4c678d12ac91deaef433bf1d32b1f87bcf",
    "colab": {},
    "colab_type": "code",
    "id": "4nTvOtd7oWJM"
   },
   "outputs": [],
   "source": [
    "def reviewToY(review):\n",
    "    return [1,0] if review.split(' ')[0] == '__label__1' else [0,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9a4aa9856bea537502506833f1df9960f6172f15",
    "colab": {},
    "colab_type": "code",
    "id": "z2DijnI-plux"
   },
   "outputs": [],
   "source": [
    "def reviewToX(review):\n",
    "    review = review.split(' ', 1)[1][:-1].lower()\n",
    "    review = re.sub('\\d','0',review)\n",
    "    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in review:\n",
    "        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c596ea6c292833146271bdf36238fd8f527a1f06"
   },
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File('../input/train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('../input/test.ft.txt.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5db1d078bb74a49c4f94cd12feb48ce52dd087a2"
   },
   "outputs": [],
   "source": [
    "train_lines = train_file.readlines()\n",
    "test_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600000, 400000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lines), len(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5af875b476a33943c6e5c7b7bc3986394e3a1fe3"
   },
   "outputs": [],
   "source": [
    "train_lines = [x.decode('utf-8') for x in train_lines]\n",
    "test_lines = [x.decode('utf-8') for x in test_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "766396c805eb0ec0bde8c7e99c3ca6212fcfebc3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5l-8fcOPljvP",
    "outputId": "ab2281fe-798d-4568-ba21-8165b6633cfc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3600000/3600000 [01:00<00:00, 59424.56it/s]\n",
      "100%|██████████| 400000/400000 [00:06<00:00, 57916.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load from the file\n",
    "reviews_train, y_train = splitReviewsLabels(train_lines)\n",
    "reviews_test, y_test = splitReviewsLabels(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "495b5ea2ed252900ea331ce7ab0cb29bba8ffd8b",
    "colab": {},
    "colab_type": "code",
    "id": "XZdy-T0mngO6"
   },
   "outputs": [],
   "source": [
    "reviews_train, y_train = shuffle(reviews_train, y_train)\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f481964b4d7579e2e8bf7c95b3e830e66fc2096b",
    "colab": {},
    "colab_type": "code",
    "id": "WwmN7WthnBgP"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "6a7453d9dc24333b89231a5244cff018de47b1fb",
    "colab": {},
    "colab_type": "code",
    "id": "fnkXf-lcQbq3"
   },
   "outputs": [],
   "source": [
    "max_features = 8192\n",
    "maxlen = 128\n",
    "embed_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "215e6317713f4db778f17b347bfc354fc619aa98",
    "colab": {},
    "colab_type": "code",
    "id": "vvzUeeZAb11p"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "8d9d66c0727b37f61015d45b865655e47910ea74",
    "colab": {},
    "colab_type": "code",
    "id": "-CZkOWKgb143"
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "63e60c5241ef89e6727bd43611766a5829c6f497",
    "colab": {},
    "colab_type": "code",
    "id": "y8HdVs3Lb2Eo"
   },
   "outputs": [],
   "source": [
    "token_train = tokenizer.texts_to_sequences(reviews_train)\n",
    "token_test = tokenizer.texts_to_sequences(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "0050e99ef94c651ffbce04277daf5fa85d87cc86",
    "colab": {},
    "colab_type": "code",
    "id": "oZMszUGKb2HP"
   },
   "outputs": [],
   "source": [
    "x_train = pad_sequences(token_train, maxlen=maxlen, padding='post')\n",
    "x_test = pad_sequences(token_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lizzie put it best: re: audio tape version. i love follett - when he gives his best effort that is - but this novel smells like quick paycheck. forgettable characters and predictable action leave the reader with the same response that heroine lizzie has to her wedding night: is that all there is? the weak title should have been a clue that this would be a second-rate effort. for a much more compelling period piece from follett, try the excellent \"a dangerous fortune\".',\n",
       " \"gratuitous sex and gore which holds no relevence.: this book is written on pure shock value. there is no plot. how was this book ever published? all this book does is disturb the reader. the subject matter of a lost generation is overdone and thus cliche'd. this book holds no relevancy as a moral work or for any genre of literature for that matter. the characters are like those of a stephen king novel: vacant. i would give the author merit for turning a first person narrative into a third person narrative b\",\n",
       " 'very short, but not all that lucid: this is a short book, and that is its only advantage, unfortunately.granted, that the author is eminent in this field and was himself a student of the great paul dirac. however, this book does not sit easily in a series designed to make a subject approachable to the novice. it has far too much esoteric maths than is good for a book of this genre. an ever stronger criticism is the fact that instead of keeping to basic physics ideas such as the double slit experiment (which',\n",
       " 'worth the subscription: aperture is indeed the preeminent art photography magazine, and consistently has enough good material to warrant a subscription independent of its clout. although ostensively devoted to art photography, many of the spreads are essentially photojournalism.if you are primarily interested in just art photography, and can subscribe only to one magazine, i would suggest \"blind spot\".',\n",
       " \"review of middleware networks: i'd like to be kind, but--it's awful. not cohesively written and very limited in its readability. a potentially useful topic treated with a heavy techno-hand...\",\n",
       " \"disjointed [stuff]: this book is 0000 pages of [stuff]. its written by about 00 people who obviously didn't look at each others segments because they repeat the same stuff over and over. if they took out all the information that was repeated throughout the book it would be about 000 pages. i was better served by the msdn documentation. wrox used to have a good reputation for solid books but it seems like quantity over quality is what they are after.\",\n",
       " \"i'm a rockabilly gal, and this just doesn't click with me: i love brian setzer's music from the stray cats up to his recent christmas cd, but this is the only cd he's ever done that i can't can't stand, no matter how much i want to like it, it just makes no sense musically or in any way what so ever. why would brian add hip hop and techno and rap to what could have been a timeless rockabilly swing cd, go figiure, skip this one, and get his christmas cd, or the dirty boogie... i find that a record is really \",\n",
       " 'fiction or junk science?: the author attempts in leaps and bounds to make causal inferences such as, \"because so-and-so plant developed on the euphrates, the region thrived culturally and economically.\" for each of these myriad statements, he skips about 00,000 mediating factors along the way, as well as 0 billion other possible explanations. the cause and effect statements as put forth in this fiction novel are dangerous, unscientific, and completely uninteresting to anyone remotely logical. this was the a',\n",
       " 'rude boy: more greats from the late and sadly missed judge.real name alex hughes.dread was owed the best part of a million pounds by his record company when it went bust.alex died of a heart attack after collapsing on stage,when the ambulance he was put in broke down.its fitting that the last people who saw him alive where the weeping skinheads who tryed in vain to push the ambulance started.he will forever be missed by all true skins.',\n",
       " 'less than expected.: this video is only 00 minutes long ( only 00 worth of abdominal exercises). even though ms. austin is very athletic and cheerful, i do not think it is worth its price. it is 0 minutes worth of exercise you have to replay everyday for two weeks at a time. not the variety i was expecting.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train_file, test_file, train_lines, test_lines\n",
    "del reviews_train, reviews_test\n",
    "del token_train, token_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "b48b02b5a43a9ea37c559ff6a76355c5c7dd1d33",
    "colab": {},
    "colab_type": "code",
    "id": "1IzD5S5u4Ban",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 32)           14368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 128, 2)            66        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 548,674\n",
      "Trainable params: 548,354\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "net = Embedding(max_features, embed_size)(input)\n",
    "net = Dropout(0.2)(net)\n",
    "net = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(32, 7, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net1 = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(2, 1)(net)\n",
    "net = GlobalAveragePooling1D()(net)\n",
    "output = Activation('softmax')(net)\n",
    "model = Model(inputs = input, outputs = output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "4232ed31bd96068f35380b9bf9c585ea2bab685e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "RaLqVOrclW57",
    "outputId": "7aaa44bc-6832-4cac-dc41-4c1a2c9b16ca",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3240000 samples, validate on 360000 samples\n",
      "Epoch 1/1\n",
      "3240000/3240000 [==============================] - 74s 23us/step - loss: 0.1914 - acc: 0.9252 - val_loss: 0.1670 - val_acc: 0.9376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f61261ce940>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)\n",
    "model.fit(x_train, y_train, batch_size=2048, epochs=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "68bf9815eefc1635f6974844ea24009c9b86f029",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9SsWJHB16o3B",
    "outputId": "99176d2b-603d-45e5-e4e7-6478dfbd4744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000/400000 [==============================] - 29s 71us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16877406593553723, 0.9369025]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "e7f2de5066fbf5218fe6266065a32fe8d1d82063"
   },
   "outputs": [],
   "source": [
    "#here need import external texts and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.9939435  0.00605653] [1 0]\n",
      "1 [9.9940443e-01 5.9552334e-04] [1 0]\n",
      "2 [0.9978258  0.00217421] [1 0]\n",
      "3 [0.33279505 0.6672049 ] [0 1]\n",
      "4 [0.9578514  0.04214856] [1 0]\n",
      "5 [9.9961358e-01 3.8646258e-04] [1 0]\n",
      "6 [0.99851745 0.00148254] [1 0]\n",
      "7 [9.9969995e-01 3.0002507e-04] [1 0]\n",
      "8 [0.6924317  0.30756825] [0 1]\n",
      "9 [0.9652173  0.03478274] [1 0]\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(x_test[:10])\n",
    "for i in range(10):\n",
    "    print(i, y_predict[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    200000\n",
       "0    200000\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_test_pd=pd.DataFrame(y_test).loc[:,0]\n",
    "y_test_pd.value_counts()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sentiment analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
